{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b324465",
   "metadata": {},
   "source": [
    "Entrenar y evaluar la preformance de una red con arquitectura U-net\n",
    "que realza una tarea de segmantacion semantica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e74c827",
   "metadata": {},
   "source": [
    "### Preanalisis de Imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d011d983",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analizando imágenes: 100%|██████████| 7393/7393 [00:25<00:00, 284.49it/s]\n",
      "Analizando máscaras: 100%|██████████| 14780/14780 [00:49<00:00, 298.74it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANÁLISIS DE IMÁGENES\n",
      "Total de imágenes: 7390\n",
      "\n",
      "Extensiones únicos:\n",
      "  .jpg: 7390\n",
      "  .mat: 3\n",
      "\n",
      "Canales únicos:\n",
      "  3: 7383\n",
      "  4: 4\n",
      "  1: 3\n",
      "Ancho promedio: 436.7, Alto promedio: 390.9\n",
      "Dimensiones mínimas: (114, 103) | máximas: (3264, 2606)\n",
      "\n",
      "ANÁLISIS DE MÁSCARAS\n",
      "Total de máscaras: 7390\n",
      "\n",
      "Extensiones únicos:\n",
      "  .png: 14780\n",
      "Ancho promedio: 436.7, Alto promedio: 390.9\n",
      "Dimensiones mínimas: (114, 103) | máximas: (3264, 2606)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "IMG_DIR = \"oxford-pets/oxford-iiit-pet/images/images\"\n",
    "MASK_DIR = \"oxford-pets/oxford-iiit-pet/annotations/annotations/trimaps\"\n",
    "\n",
    "img_exts = []\n",
    "mask_exts = []\n",
    "img_shapes = []\n",
    "mask_shapes = []\n",
    "img_channels = []\n",
    "\n",
    "# Analizar imágenes\n",
    "for f in tqdm(os.listdir(IMG_DIR), desc=\"Analizando imágenes\"):\n",
    "    path = os.path.join(IMG_DIR, f)\n",
    "    ext = os.path.splitext(f)[1].lower()\n",
    "    img_exts.append(ext)\n",
    "    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    if img is None:\n",
    "        continue\n",
    "    h, w = img.shape[:2]\n",
    "    c = 1 if len(img.shape) == 2 else img.shape[2]\n",
    "    img_shapes.append((w, h))\n",
    "    img_channels.append(c)\n",
    "\n",
    "# Analizar máscaras\n",
    "for f in tqdm(os.listdir(MASK_DIR), desc=\"Analizando máscaras\"):\n",
    "    path = os.path.join(MASK_DIR, f)\n",
    "    ext = os.path.splitext(f)[1].lower()\n",
    "    mask_exts.append(ext)\n",
    "    m = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    if m is None:\n",
    "        continue\n",
    "    mask_shapes.append(m.shape[:2])\n",
    "\n",
    "def resumen(lista, name):\n",
    "    c = Counter(lista)\n",
    "    print(f\"\\n{name} únicos:\")\n",
    "    for k, v in c.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "\n",
    "print(\"ANÁLISIS DE IMÁGENES\")\n",
    "print(f\"Total de imágenes: {len(img_shapes)}\")\n",
    "resumen(img_exts, \"Extensiones\")\n",
    "resumen(img_channels, \"Canales\")\n",
    "\n",
    "w, h = zip(*img_shapes)\n",
    "print(f\"Ancho promedio: {np.mean(w):.1f}, Alto promedio: {np.mean(h):.1f}\")\n",
    "print(f\"Dimensiones mínimas: ({min(w)}, {min(h)}) | máximas: ({max(w)}, {max(h)})\")\n",
    "\n",
    "print(\"\\nANÁLISIS DE MÁSCARAS\")\n",
    "print(f\"Total de máscaras: {len(mask_shapes)}\")\n",
    "resumen(mask_exts, \"Extensiones\")\n",
    "\n",
    "mw, mh = zip(*[(s[1], s[0]) for s in mask_shapes])\n",
    "print(f\"Ancho promedio: {np.mean(mw):.1f}, Alto promedio: {np.mean(mh):.1f}\")\n",
    "print(f\"Dimensiones mínimas: ({min(mw)}, {min(mh)}) | máximas: ({max(mw)}, {max(mh)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe206137",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(img_channels)):\n",
    "    if img_channels == 4:\n",
    "        plt.imshow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7378b807",
   "metadata": {},
   "source": [
    "### Red U-NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e40474-0721-4f57-8847-895d7755972b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Parámetros\n",
    "IMG_SIZE = 128\n",
    "BATCH_SIZE = 16\n",
    "NUM_CLASSES = 3\n",
    "EPOCHS = 100\n",
    "VAL_SPLIT = 0.15\n",
    "TEST_SPLIT = 0.15\n",
    "\n",
    "IMAGES_DIR = r\"C:\\Users\\anapa\\Documents\\DeepLearning\\Practica_3\\oxford-pets\\oxford-iiit-pet\\images\\images\"\n",
    "MASKS_DIR  = r\"C:\\Users\\anapa\\Documents\\DeepLearning\\Practica_3\\oxford-pets\\oxford-iiit-pet\\annotations\\annotations\\trimaps\"\n",
    "\n",
    "# Cargar y emparejar archivos\n",
    "all_images = sorted([\n",
    "    os.path.join(IMAGES_DIR, f)\n",
    "    for f in os.listdir(IMAGES_DIR)\n",
    "    if f.endswith(\".jpg\") and not f.endswith(\".mat\")\n",
    "])\n",
    "\n",
    "all_masks = sorted([\n",
    "    os.path.join(MASKS_DIR, f)\n",
    "    for f in os.listdir(MASKS_DIR)\n",
    "    if f.endswith(\".png\") and not f.startswith(\"._\")\n",
    "])\n",
    "\n",
    "# Asegurarnos de que tengan la misma longitud\n",
    "assert len(all_images) == len(all_masks), \"Cantidad de imágenes y máscaras no coincide\"\n",
    "\n",
    "# Dividir en train / val / test\n",
    "data = list(zip(all_images, all_masks))\n",
    "random.shuffle(data)\n",
    "n_total = len(data)\n",
    "n_test = int(TEST_SPLIT * n_total)\n",
    "n_val = int(VAL_SPLIT * n_total)\n",
    "n_train = n_total - n_val - n_test\n",
    "\n",
    "train_data = data[:n_train]\n",
    "val_data = data[n_train:n_train+n_val]\n",
    "test_data = data[n_train+n_val:]\n",
    "\n",
    "# Función para cargar imagen y máscara\n",
    "def load_image_mask(image_path, mask_path):\n",
    "    # Imagen\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.io.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "\n",
    "    # Máscara\n",
    "    mask = tf.io.read_file(mask_path)\n",
    "    mask = tf.io.decode_png(mask, channels=1)\n",
    "    mask = tf.image.resize(mask, [IMG_SIZE, IMG_SIZE], method='nearest')\n",
    "    mask = tf.cast(mask, tf.int32) - 1  # de (1,2,3) -> (0,1,2)\n",
    "    return image, mask\n",
    "\n",
    "def create_tf_dataset(data_list, batch_size=BATCH_SIZE):\n",
    "    image_paths, mask_paths = zip(*data_list)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((list(image_paths), list(mask_paths)))\n",
    "    dataset = dataset.map(load_image_mask, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# Crear datasets\n",
    "train_dataset = create_tf_dataset(train_data)\n",
    "val_dataset   = create_tf_dataset(val_data)\n",
    "test_dataset  = create_tf_dataset(test_data)\n",
    "\n",
    "# Bloque convolucional\n",
    "def conv_block(inputs, filters):\n",
    "    x = layers.Conv2D(filters, 3, padding='same', activation='relu')(inputs)\n",
    "    x = layers.Conv2D(filters, 3, padding='same', activation='relu')(x)\n",
    "    return x\n",
    "\n",
    "# Modelo U-Net\n",
    "def unet_model(input_size=(IMG_SIZE, IMG_SIZE, 3), num_classes=NUM_CLASSES):\n",
    "    inputs = layers.Input(input_size)\n",
    "\n",
    "    # Encoder\n",
    "    c1 = conv_block(inputs, 64)\n",
    "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = conv_block(p1, 128)\n",
    "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = conv_block(p2, 256)\n",
    "    p3 = layers.MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = conv_block(p3, 512)\n",
    "    p4 = layers.MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    # Bottleneck\n",
    "    c5 = conv_block(p4, 1024)\n",
    "\n",
    "    # Decoder\n",
    "    u6 = layers.Conv2DTranspose(512, 2, strides=2, padding='same')(c5)\n",
    "    u6 = layers.concatenate([u6, c4])\n",
    "    c6 = conv_block(u6, 512)\n",
    "\n",
    "    u7 = layers.Conv2DTranspose(256, 2, strides=2, padding='same')(c6)\n",
    "    u7 = layers.concatenate([u7, c3])\n",
    "    c7 = conv_block(u7, 256)\n",
    "\n",
    "    u8 = layers.Conv2DTranspose(128, 2, strides=2, padding='same')(c7)\n",
    "    u8 = layers.concatenate([u8, c2])\n",
    "    c8 = conv_block(u8, 128)\n",
    "\n",
    "    u9 = layers.Conv2DTranspose(64, 2, strides=2, padding='same')(c8)\n",
    "    u9 = layers.concatenate([u9, c1])\n",
    "    c9 = conv_block(u9, 64)\n",
    "\n",
    "    outputs = layers.Conv2D(num_classes, 1, activation='softmax')(c9)\n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Metrica IoU personalizada\n",
    "def iou_metric(y_true, y_pred):\n",
    "    \"\"\"IoU promedio para etiquetas enteras (sparse).\"\"\"\n",
    "    y_pred = tf.argmax(y_pred, axis=-1)  # clase predicha\n",
    "    y_true = tf.squeeze(y_true, axis=-1)  # elimina canal de máscara\n",
    "    y_pred = tf.cast(y_pred, tf.int32)\n",
    "    y_true = tf.cast(y_true, tf.int32)\n",
    "\n",
    "    iou_list = []\n",
    "    for i in range(NUM_CLASSES):\n",
    "        intersection = tf.reduce_sum(tf.cast(tf.equal(y_true, i) & tf.equal(y_pred, i), tf.float32))\n",
    "        union = tf.reduce_sum(tf.cast((tf.equal(y_true, i) | tf.equal(y_pred, i)), tf.float32))\n",
    "        iou = tf.where(union == 0, 1.0, intersection / union)\n",
    "        iou_list.append(iou)\n",
    "    return tf.reduce_mean(iou_list)\n",
    "\n",
    "iou_metric.__name__ = 'iou_metric'\n",
    "\n",
    "# Compilar modelo\n",
    "model = unet_model()\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy', iou_metric])\n",
    "model.summary()\n",
    "\n",
    "# Early stopping\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True)\n",
    "\n",
    "# Entrenamiento\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stop])\n",
    "\n",
    "# Graficar métricas\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Loss por época')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "plt.title('Accuracy por época')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# IoU\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history.history['iou_metric'], label='Train IoU')\n",
    "plt.plot(history.history['val_iou_metric'], label='Val IoU')\n",
    "plt.title('Mean IoU por época')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Mean IoU')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluar en train / val / test\n",
    "train_metrics = model.evaluate(train_dataset, verbose=0)\n",
    "val_metrics = model.evaluate(val_dataset, verbose=0)\n",
    "test_metrics = model.evaluate(test_dataset, verbose=0)\n",
    "\n",
    "metric_names = model.metrics_names\n",
    "print(\"\\nResultados finales:\")\n",
    "print(f\"Entrenamiento:\")\n",
    "for name, value in zip(metric_names, train_metrics):\n",
    "    print(f\"  {name:25s}: {value:.4f}\")\n",
    "\n",
    "print(f\"\\nValidación:\")\n",
    "for name, value in zip(metric_names, val_metrics):\n",
    "    print(f\"  {name:25s}: {value:.4f}\")\n",
    "\n",
    "print(f\"\\nTest:\")\n",
    "for name, value in zip(metric_names, test_metrics):\n",
    "    print(f\"  {name:25s}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b172099",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(\n",
    "    model,\n",
    "    to_file=\"unet_architecture.png\",\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    show_layer_activations=True,\n",
    "    dpi=98\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0897206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(model, dataset, num_classes=NUM_CLASSES):\n",
    "    \"\"\"\n",
    "    Calcula Accuracy e IoU promedio para un dataset dado.\n",
    "    \n",
    "    Args:\n",
    "        model: modelo entrenado\n",
    "        dataset: tf.data.Dataset con imágenes y máscaras\n",
    "        num_classes: cantidad de clases en la segmentación\n",
    "\n",
    "    Returns:\n",
    "        mean_acc: Accuracy promedio\n",
    "        mean_iou: IoU promedio\n",
    "    \"\"\"\n",
    "    all_accs = []\n",
    "    all_ious = []\n",
    "\n",
    "    for images, masks in dataset:\n",
    "        # Predicciones\n",
    "        preds = model.predict(images, verbose=0)\n",
    "        preds_classes = tf.argmax(preds, axis=-1)\n",
    "        \n",
    "        # Asegurar que ambos tensores tengan el mismo tipo\n",
    "        preds_classes = tf.cast(preds_classes, tf.int32)\n",
    "        masks_squeezed = tf.cast(tf.squeeze(masks, axis=-1), tf.int32)\n",
    "\n",
    "        # --- Accuracy ---\n",
    "        acc = tf.reduce_mean(tf.cast(preds_classes == masks_squeezed, tf.float32))\n",
    "        all_accs.append(acc)\n",
    "\n",
    "        # --- IoU por clase ---\n",
    "        iou_list = []\n",
    "        for i in range(num_classes):\n",
    "            intersection = tf.reduce_sum(\n",
    "                tf.cast((preds_classes == i) & (masks_squeezed == i), tf.float32)\n",
    "            )\n",
    "            union = tf.reduce_sum(\n",
    "                tf.cast((preds_classes == i) | (masks_squeezed == i), tf.float32)\n",
    "            )\n",
    "            iou = tf.where(union == 0, 1.0, intersection / union)\n",
    "            iou_list.append(iou)\n",
    "        mean_iou_batch = tf.reduce_mean(iou_list)\n",
    "        all_ious.append(mean_iou_batch)\n",
    "\n",
    "    mean_acc = tf.reduce_mean(all_accs).numpy()\n",
    "    mean_iou = tf.reduce_mean(all_ious).numpy()\n",
    "\n",
    "    return mean_acc, mean_iou\n",
    "\n",
    "train_acc, train_iou = compute_metrics(model, train_dataset)\n",
    "val_acc, val_iou     = compute_metrics(model, val_dataset)\n",
    "test_acc, test_iou   = compute_metrics(model, test_dataset)\n",
    "\n",
    "print(f\"Train -> Accuracy: {train_acc:.4f}, IoU: {train_iou:.4f}\")\n",
    "print(f\"Val   -> Accuracy: {val_acc:.4f}, IoU: {val_iou:.4f}\")\n",
    "print(f\"Test  -> Accuracy: {test_acc:.4f}, IoU: {test_iou:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a39c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de predicciones con métricas\n",
    "def show_predictions(model, dataset, num=3):\n",
    "    for images, masks in dataset.take(10):\n",
    "        preds = model.predict(images)\n",
    "        preds = tf.argmax(preds, axis=-1)\n",
    "        preds = preds[..., tf.newaxis]\n",
    "\n",
    "        for i in range(num):\n",
    "            img = tf.cast(images[i], tf.uint8)\n",
    "            true_mask = tf.cast(masks[i], tf.int32)\n",
    "            pred_mask = tf.cast(preds[i], tf.int32)\n",
    "\n",
    "            # Calcular métricas\n",
    "            # Accuracy pixel a pixel\n",
    "            acc = tf.reduce_mean(\n",
    "                tf.cast(tf.equal(true_mask, pred_mask), tf.float32)\n",
    "            ).numpy()\n",
    "\n",
    "            # IoU\n",
    "            intersection = tf.reduce_sum(\n",
    "                tf.cast(tf.equal(true_mask, pred_mask) & (true_mask > 0), tf.float32)\n",
    "            )\n",
    "            union = tf.reduce_sum(\n",
    "                tf.cast((true_mask > 0) | (pred_mask > 0), tf.float32)\n",
    "            )\n",
    "            iou = (intersection / union).numpy() if union > 0 else 1.0\n",
    "\n",
    "            # --- Mostrar imágenes ---\n",
    "            plt.figure(figsize=(12, 4))\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(img)\n",
    "            plt.title(\"Imagen\")\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.imshow(tf.squeeze(true_mask))\n",
    "            plt.title(\"Máscara real\")\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.imshow(tf.squeeze(pred_mask))\n",
    "            plt.title(\"Predicción\")\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.suptitle(\n",
    "                f\"Accuracy: {acc:.3f}   |   IoU: {iou:.3f}\",\n",
    "                fontsize=12, y=0.005\n",
    "            )\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "show_predictions(model, test_dataset, num=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
